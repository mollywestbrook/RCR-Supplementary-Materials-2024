Tom Kocher’s Interview:

Okay. So, I started reading the paper this morning, but I didn't get a chance to finish it. But I think one of the things that I saw that was Intriguing to me, was that. Most of the students said that they found AI useful. Um, in the Course of the assignment.

Um, Do you think you could talk a little bit about Their opinions about it and how they found it useful.

You know. I was pretty arms like that whole thing. Oh, We tried to guide them into For me, the project was Trying to get the students to explore A. With, it was useful because there's a lot of Talk. Essentially misinformation about it. And so, We were as interested in showing them.

The deficiencies as. Much as showing the utility.

So, I think That they Generally like having AI do something to fill the page. Let's first starter. So they don't have to Start with a blank page. But then what we try to impress upon that was that there's a lot they can do to make it better. And also that there's a lot that they can do with the prompts to make the AI output better.

And both of those require.

So, some of them Got that message and others just went through the assign. Um, One of the other things I was thinking about. Because I know you do a lot of collaborative projects and share a lot of data sets, collaboratively. Is in thinking about the ethics of how A lot of these models gather data.

Using certain programs to house data online allows access for AIS to kind of like draw the internet. Do you have any thoughts about? Well obviously, this is like Pretty ethically, not okay. Um, But do you have any thoughts about how that might affect? Um, Data sharing in the next couple of years or how people go.

Do you think people are mostly going to ignore it? Do you think it's going to become more of a problem? Things like that. So, I would say that. The kinds of data that we're generating are mostly DNA sequences. There is a. Strong history tradition. And more reasons about, Not using.

Dna sequence data that. The positive and then CBI. Until? People generated that they'd have written their paper.

I still worry about that a little bit and I make sure that in CPI keeps my data. Private, until My paper comes out.

But General. Worries about that kind of priority. A big concern. The raw sequence data. Too much for anybody generally at least on the work that I'm doing. Um, So what kinds of research? Might that be a problem. I mean, I think it's much more. Ideas. I tend not to deposit things in the preprint servers, because to me, that's my most important product of the ideas and I don't want anybody taking those ideas.

Reading your own paper. That's antisocial me. I should. Humanity to, you know, develop these ideas as quickly as possible, but I want to make sure that that idea gets presented the way. I think it should be presented, not only somebody else wants it to be presented. All right, to cherry pick.

So, I don't At least in my field. I don't see. A huge problem of that.

He's trying to think about.

Yeah. Um, Do you think? Those like, Not so much for your undergraduate students. But for grad students, postdocs in the lab Um, In the next couple of years, do you think those types of practice are going to be more? They're already, you know, good data management and Cyber security are already pretty important things to practice, but do you think those teachings may have to change in the next couple of years?

If Things like this continue.

Yeah, I guess.

I'm just trying to imagine scenarios where Hey, I gets a hold of my data and comes to completely separate stupid conclusions. And whether We need to be guarding against that. I guess I see more of an opportunity for my students. To use AI tools to mine. The literature. In ways that it's not.

Doing very well yet. I don't feel like those tools are there but I can imagine. Ways that AI could. Process, the data for. For a whole field. And generates. Yeah, yeah, yeah. I can generate some new hypotheses but it can summarize the data in a way that Those were the tools.

I think that Kristen was putting together that I found the most useful were most of the research oriented tools, unless the actual Raining and generative AI tools at least for my own. For my own purpose. Right, you know, so Anthony Joseph's right now. He's done a bunch of. Work, where collect?

100 papers and we collect. The gene expression tables from those. Under different experiments in this field. And now he wants to know, Which genes? Changed in their expression pattern across. A whole bunch of different experimental manipulations. So, they found that And then he found out that those Jeans. Clustered.

And the three or four clusters and all the Publications so far in this field, have been in this one cluster and not the other two clusters. And he sees this as a very general tool that could be used. Everybody should be using this to prioritize with the next experiment is I don't think we have an AI tool to do exactly what he's done.

But, I could see that those tools could develop in the next couple of years. Um, Are there any other other any other thoughts that you have? In terms of specifically Ai and the interaction of data acquisition and management.

I was trying to think. In my own. Field. Whether There's data and then CPI, that could be mined I think you're right. Maybe we don't yet have a tool. That raw sequences. Be that useful. But, Writing about them, I think is much more as It's a place where that those that knowledge that could be done with expression data.

Yeah. Bank. But there have been a lot of tools. To do that. Um,

I was talking also with Anthony the other day about, Just how useless go annotation is. All right, so there's an early application of AI essentially. And, It's just stupid.

So, there's that. Um,

I don't know if it's smart. Every day I get notifications of papers that have been published and that dutifully save the PDFs to my desktop and once a month, I clear all those papers off from my desktop into a folder saying to read. February 2024. Maybe. Read the abstracts of those papers while I'm downloading.

But,

You know, maybe. For my desktop. That I could say, you know, Look through this hard drive of all these papers I've collected and tell me. Find all the papers that discuss these this search. It's some more intelligent way than just a simple search. And applying that to the whole.

Did a bit about my database. I see that as a task that I can't keep up with that. Maybe AI could help with. But I don't.

The question is, How much am I going to trust AI summaries of that data? Versus just giving me a shorter pile of papers to read. Because I could easily see how I mean, I'm trying to read these papers to get something new out of it, that the authors didn't see, and AI is only going to get what the authors see.

So it's the new synthesis that I can tell AI. How to make it. It's not gonna get over based on where dissociation. If there was any place,

It would be the help lead manage the reading not the writing. Writing still pain in the neck.

Good writing. Requires, you know, Thinking about so many other factors. And just let the usual order of work is Whatever. Whatever piece of writing AI may provide is not the only piece in putting together a manuscript. I mean you're also looking having other people look at the manu, script, you yourself, are looking at it.

Oh yeah. I don't think that's going to change, even if Grammar tools become more accurate. Yeah, I mean The things I write are generally pretty clean according to words, Grammar. And then you go in and okay, Yeah, that's better than that. The Word wants to do it, but there's other places where no, that's that's not how I want to use the fluctuation in the room.

Um,

Yeah, so I haven't really experimented by I don't know how I would do this. If I have finished a new study and I want to First draft from AI, To fill in the blank pages and then I go and start to revise that I don't know that there's a tool that can

From my data tables. And write a paper. Maybe there is, but Well, the assignment that Kristen developed was exclusively creative. So there was never a piece that took data, and Synthesized it into a text. And that is potentially a piece that,

Not trustworthy yet. Or if it ever will be trustworthy. Yeah, and I'm just trying to decide whether It would be helpful to have AI. Write some kind of first draft that I edited or whether that would slow me down. Yeah, I see no way for AI to do that.

Yeah. I think that's good. Okay, I think you


Philip Johnson’s Interview:


Um, So I emailed you, the questions, some of the questions I have added a couple of um like addendums to a couple of them but you the reason that I was interested in interviewing you specifically is because you do a lot of computational research and I was curious if The for I'll start with the first question, which is Have you had any success in using computational AI techniques in your research?

And here, I'm talking about things like unsupervised, learning algorithms, machine learning, artificial, Those types of. Ai. Yes, can you talk a little bit about, right? Some of those experiences. I mean, Aa is now kind of a catch word, has this machine learning nice meeting again. Great to meet you.

Um, Sort of catchphrase for all sorts of. Largely statistical models. And The models that we've had success with. Predictive models. We've had success. With my research have been random for us and convolutional neural Nets. We've used those always in a Supervise context where we've had some training data. And we were trying to identify.

Factors that can be used to. Classify sign. Want to be able to classify new data. And identify the, The factors that drove that classification. One of the challenges with These sorts of algorithms, particularly in the neural maps is Understanding. Not treating it just as a black box, but understanding the factors inside that black box.

Was like, you need the prediction that it makes. Broadly, that's called interpretability. And there are various. Approaches or trying to interpret what's going on? Inside a convolutionary, neural Nets parameters. We've used some of those techniques with some success. There's no silver bullets. In terms of interpability. Do you think that?

As a follow-up. Zoo black box, Ness of some of these algorithms is Maybe important to consider in terms of the ethics of elucidating that research to other people.

This is someone. This may sound biased. I would say not in the way that we have used his options. Yeah,

World. When it's very it's a reproducible in the sense, it's clear what data was used to train the model? Even if we don't Publish the parameters to the model because that's not particularly. Interesting. That's used. Reach, this parameters model is published. So when you come on that method with the right data then you can reproduce I would say it's not an ethical issue, but more of a usefulness issue, is this useful to science?

If I can predict something, but I don't understand why my prediction. Yeah is what it is. Then, I'm not sure that, that's a very useful contribution to Human science at least since Tend to be all about. Why questions?

Yeah, it is what drives and given outcome towards One Direction versus another Direction. Yeah. And if you have no way to even approach that question then, Is it useful to know that we can predict it? Yeah. Maybe a very limited. Um, is there like a concrete example, where you found something where you were?

Like we can do this but there's not really a point. Or. Beyond, just the fact that There's not really a used to the protections that we've made. Point have you kind of done so many of these iterations? That it's And,

There are a couple projects. That we're working on right now, where You're using convolutional neural Nets. And we are getting results that vary from Excellent. Predictive performance on test data. To. Better than random but not incredible performance. And, We are currently struggling with how to Best. Interpret it. Yeah.

Because

We know what data went into the model, we can say. There's definitely a signal in these sequences or there's definitely a signal in this. Region of the genome, but we don't know how These positions are interacting with each other. And it seems like it is some sort of non-linear interaction that's causing this.

It's not just a simple because a linear model doesn't predict this. Well So, there is a question of how much? What can we do with this? Yeah. Is this interesting to other people to publish? If we're just saying information is in there, but we don't really know why. Yeah.

I guess that wasn't really a specific. It was just telling you, There are those are our actual scenarios that we have now. Yeah, Um, I'll move on, I think from that particular. Aspect of this. Uh, large language models. Which is something that has kind of emerged in the past like two years.

Have you used llms as part of your research process in any way? Why? Or why not? They haven't been seemed directly relevant. Do you have a student? Who has explored your Transformer models, which is the structure that a lot of the lms use. But, We've not found a particular application.

Um you also teach and I think students use of llms has come in to kind of the conversation in education. Have you had any experience with students using llms in your class to success or not? Success? I know students used it in my statistics class last. I exposedly said it was fine for them to use it.

I said that I wasn't sure what it would be helpful. But I said there, I had no problem with them. Using that wife philosophy is it's just another resource that's out there. I think Minecraft would be a good thing. I have not used it myself but I had students.

Show me things that they asked chat GBT. And, Sometimes it gave output that I would say was useful. Sometimes they've output that I would say, was it misinterpreted. What question was asking? And, This either due to The user. Student, not really understanding the question, the situation, the problem. Well enough to ask GPD.

Yeah. Or from chat GPT. Working perfectly. Yeah, some combination of the two. I, I don't see. I think we're a long ways away from large language, models, being able to really Get your Idea, without you, clearly articulating it That's hard enough for humans. Do right conversation. When the human has all sorts of other clues as to and can ask ball of questions to ask what the intent is.

So I think that right now, The chat GPT like tools. Require you to have a comfortable knowledge note, what to ask? And how to interpret the result? So, And that perspective, I think it's fine for use in class because You, if you understand it, well enough to know how to ask, chap, GPT and how to interpret what it gives you back.

Then you understand it well enough. Um, Okay, so Specifically about some of the ethical considerations of how AI is currently being used. Um, Right now, certain AI. Specifically, llms are kind of scraping publicly available. Works. And potentially also, Data sets. Do you? Have any concerns regarding that kind of How those algorithms are being used and how they are Gathering data.

At least for your own. I mean, you generate a lot of data sets, would you have any concerns? If? Those data were kind of your own original ideas, were scraped for an llm. Now, and understand better. Well, the question? Yes. It was. First of the team, like at all kind of help you with something.

The short answer is no, that is not something that has bothered. That I have. Thought of is bothering me personally.

I generally think of, when I, once I publish it in idea that it's public domain and I'm happy to share it with anyone or anything.

I think science is in different sort of creative process, then. The Arts and, um, Yeah, like literature or sort of way. So, I think the Annette science Very naturally has this collaborative aspect of like, once it's out sharing everyone sharing with each other. And there's no royalty payment for the use of Ideas.

So, I'm not Immediately seeing a ethical problem with Ai going through research papers. Do you think there is? Any situation? Where? Raw data that you have gathered could be taken out of context. Oh, there are all sorts of situations where science? Things could be taken out of context. Personally, I have, I don't Generate much data myself, have a complicational Lab.

And so, It's all through collaborators that I have. Any data that I publish has been through. I think, oh, there are a lot of things involving. Human Origins and human genetics. That could be Taken out of context and Manipulated, but that's always been the case. I've done work on.

Immunology. Connection. Immune responses after a. Stimulus. That could be taken as a condemnation of vaccines, if you were selective about how responsive It's not. I know that doesn't come through. The truck doesn't come.

I don't see. Ai. Scraping research as being a Bigger threat. Taking research out of context than it was before. Yeah. Um, Okay, so the last question that I have because there's also my topic as data, acquisition and management. Are there any AI tools? That you use for data management or collaboration with other people or if you didn't don't have any where what you think it could come in handy.

At this point, I'm not seeing where it would be. Yeah.

Do you think it management? I think of is Mostly about organizing where you're recording data. And, The data sets, I've worked with have all been clear enough. About how they were organized. That that wasn't a massive task. Require assistance. Um, do you think it could come in handy with like, Helping synthesize obviously, it's not quite there yet but synthesizing like scientific literature.

Um, in any way. Do you think that?

I think that would be a very dangerous that this state that it is now dangerous as Have enough. Want to be reading that summary and taking it as There's just too much hallucination now. And until that problem is solved, I don't This being a useful. Just out of more out of curiosity.

Because you, Have your lamp has kind of investigated the underlying structure of llms is there like any sort of way to Fix the hallucination problem. I'm not the right person, though. Yeah. To answer that. That's okay. There are a lot of very smart people working on. Yeah. I'll give it a dad.

People. Look at that much more than I have. Yeah. I feel qualified into.

Those are all the questions that I have.
